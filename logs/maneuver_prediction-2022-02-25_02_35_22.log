2022-02-25 02:36:24,164 - ### Training Machine Ip address ###
 192.168.0.7

2022-02-25 02:36:24,164 - ### Model summary below###
 BackBone(
  (encoder): Encoder(
    (groups): ModuleList(
      (0): Sequential(
        (0): Res1d(
          (conv1): Conv1d(3, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (relu): ReLU(inplace=True)
          (bn1): GroupNorm(1, 32, eps=1e-05, affine=True)
          (bn2): GroupNorm(1, 32, eps=1e-05, affine=True)
          (downsample): Sequential(
            (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)
            (1): GroupNorm(1, 32, eps=1e-05, affine=True)
          )
        )
        (1): Res1d(
          (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (relu): ReLU(inplace=True)
          (bn1): GroupNorm(1, 32, eps=1e-05, affine=True)
          (bn2): GroupNorm(1, 32, eps=1e-05, affine=True)
        )
      )
      (1): Sequential(
        (0): Res1d(
          (conv1): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
          (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (relu): ReLU(inplace=True)
          (bn1): GroupNorm(1, 64, eps=1e-05, affine=True)
          (bn2): GroupNorm(1, 64, eps=1e-05, affine=True)
          (downsample): Sequential(
            (0): Conv1d(32, 64, kernel_size=(1,), stride=(2,), bias=False)
            (1): GroupNorm(1, 64, eps=1e-05, affine=True)
          )
        )
        (1): Res1d(
          (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (relu): ReLU(inplace=True)
          (bn1): GroupNorm(1, 64, eps=1e-05, affine=True)
          (bn2): GroupNorm(1, 64, eps=1e-05, affine=True)
        )
      )
      (2): Sequential(
        (0): Res1d(
          (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
          (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (relu): ReLU(inplace=True)
          (bn1): GroupNorm(1, 128, eps=1e-05, affine=True)
          (bn2): GroupNorm(1, 128, eps=1e-05, affine=True)
          (downsample): Sequential(
            (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
            (1): GroupNorm(1, 128, eps=1e-05, affine=True)
          )
        )
        (1): Res1d(
          (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (relu): ReLU(inplace=True)
          (bn1): GroupNorm(1, 128, eps=1e-05, affine=True)
          (bn2): GroupNorm(1, 128, eps=1e-05, affine=True)
        )
      )
    )
    (lateral): ModuleList(
      (0): Conv1d(
        (conv): Conv1d(32, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
        (norm): GroupNorm(1, 256, eps=1e-05, affine=True)
        (relu): ReLU(inplace=True)
      )
      (1): Conv1d(
        (conv): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
        (norm): GroupNorm(1, 256, eps=1e-05, affine=True)
        (relu): ReLU(inplace=True)
      )
      (2): Conv1d(
        (conv): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
        (norm): GroupNorm(1, 256, eps=1e-05, affine=True)
        (relu): ReLU(inplace=True)
      )
    )
    (output): Res1d(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (relu): ReLU(inplace=True)
      (bn1): GroupNorm(1, 256, eps=1e-05, affine=True)
      (bn2): GroupNorm(1, 256, eps=1e-05, affine=True)
    )
  )
  (autoregressive): AutoRegressive(
    (gru): GRU(256, 128, batch_first=True)
  )
  (Wk): ModuleList(
    (0): Linear(in_features=128, out_features=256, bias=True)
    (1): Linear(in_features=128, out_features=256, bias=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): Linear(in_features=128, out_features=256, bias=True)
    (4): Linear(in_features=128, out_features=256, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=128, out_features=256, bias=True)
    (7): Linear(in_features=128, out_features=256, bias=True)
    (8): Linear(in_features=128, out_features=256, bias=True)
    (9): Linear(in_features=128, out_features=256, bias=True)
  )
  (softmax): Softmax(dim=None)
  (lsoftmax): LogSoftmax(dim=None)
)

2022-02-25 02:36:24,165 - ===> Configuration parameter
                                    GPU_id: 0
                                    batch_size: 64
                                    epoch: 300
                                    n_warmup_steps: 30
                                    validataion_period: 5
                                    ckpt_period: 10
                                    ckpt_dir: C:\Users\VDCLAB\Desktop\hs\HMC_prediction/ckpt/
                                    data_dir_train: C:\Users\VDCLAB\Desktop\hs\HMC_prediction/data/drone_data/processed/train/
                                    data_dir_val: C:\Users\VDCLAB\Desktop\hs\HMC_prediction/data/drone_data/processed/val/
                                    data_dir_orig: C:\Users\VDCLAB\Desktop\hs\HMC_prediction/data/drone_data/processed/archive/
                                    occlusion_rate: 0.2
                                    splicing_num: 128
                                    LC_multiple: 5
                                    FOV: 30
                                    interpolate: False
                                    max_pred_time: 5
                                    max_hist_time: 10
                                    hz: 2
                                    val_rate: 0.2
                                    n_hidden_after_deconv: 256
                                    n_convgru_layer: 1
                                    convgru_kernel_size: (3, 3)
                                    convgru_output_layer_num: 4
                                    convgru_output_channel_list: [16, 32, 64, 128]
                                    convgru_output_kernel_size_list: [5, 5, 5, 5]
                                    log_dir: logs/

2022-02-25 02:36:24,165 - ===> Model total parameter: 1283392
2022-02-25 02:36:24,165 - ===> Model Training Start
2022-02-25 02:49:59,343 - ===> Train Epoch: 1 	 Accuracy: 42.92%	Loss: 1.39928532
2022-02-25 03:03:29,932 - ===> Train Epoch: 2 	 Accuracy: 64.70%	Loss: 0.77727956
2022-02-25 03:17:00,024 - ===> Train Epoch: 3 	 Accuracy: 71.63%	Loss: 0.62096834
2022-02-25 03:30:29,922 - ===> Train Epoch: 4 	 Accuracy: 75.70%	Loss: 0.52988511
2022-02-25 03:44:00,061 - ===> Train Epoch: 5 	 Accuracy: 78.65%	Loss: 0.45845112
2022-02-25 03:45:43,497 - ===> Validation after Training epoch: 5 	 Accuracy: 30.01%	Loss: 2.63832307
2022-02-25 03:59:14,723 - ===> Train Epoch: 6 	 Accuracy: 81.33%	Loss: 0.40466273
2022-02-25 04:12:45,562 - ===> Train Epoch: 7 	 Accuracy: 83.46%	Loss: 0.36320367
2022-02-25 04:26:16,147 - ===> Train Epoch: 8 	 Accuracy: 85.37%	Loss: 0.32048404
2022-02-25 04:39:46,465 - ===> Train Epoch: 9 	 Accuracy: 86.74%	Loss: 0.29145032
2022-02-25 04:53:16,745 - ===> Train Epoch: 10 	 Accuracy: 88.26%	Loss: 0.26545286
2022-02-25 04:54:59,638 - ===> Validation after Training epoch: 10 	 Accuracy: 27.98%	Loss: 3.70255113
2022-02-25 05:08:29,704 - ===> Train Epoch: 11 	 Accuracy: 89.54%	Loss: 0.24418335
2022-02-25 05:21:59,936 - ===> Train Epoch: 12 	 Accuracy: 90.39%	Loss: 0.23041424
2022-02-25 05:35:30,106 - ===> Train Epoch: 13 	 Accuracy: 91.24%	Loss: 0.21326061
2022-02-25 05:49:00,369 - ===> Train Epoch: 14 	 Accuracy: 92.15%	Loss: 0.19725676
2022-02-25 06:02:30,843 - ===> Train Epoch: 15 	 Accuracy: 92.62%	Loss: 0.18685023
2022-02-25 06:04:13,826 - ===> Validation after Training epoch: 15 	 Accuracy: 26.96%	Loss: 4.35591841
2022-02-25 06:17:44,386 - ===> Train Epoch: 16 	 Accuracy: 93.28%	Loss: 0.17939965
2022-02-25 06:31:14,601 - ===> Train Epoch: 17 	 Accuracy: 93.78%	Loss: 0.16598332
2022-02-25 06:44:44,735 - ===> Train Epoch: 18 	 Accuracy: 94.12%	Loss: 0.16005315
2022-02-25 06:58:15,095 - ===> Train Epoch: 19 	 Accuracy: 94.43%	Loss: 0.15148792
2022-02-25 07:11:45,393 - ===> Train Epoch: 20 	 Accuracy: 94.78%	Loss: 0.14681986
2022-02-25 07:13:28,333 - ===> Validation after Training epoch: 20 	 Accuracy: 27.69%	Loss: 4.76016331
2022-02-25 07:26:58,644 - ===> Train Epoch: 21 	 Accuracy: 95.06%	Loss: 0.14048126
2022-02-25 07:40:29,285 - ===> Train Epoch: 22 	 Accuracy: 95.07%	Loss: 0.13594514
2022-02-25 07:53:59,721 - ===> Train Epoch: 23 	 Accuracy: 95.41%	Loss: 0.13039461
2022-02-25 08:07:30,299 - ===> Train Epoch: 24 	 Accuracy: 95.65%	Loss: 0.12654763
2022-02-25 08:21:00,965 - ===> Train Epoch: 25 	 Accuracy: 95.66%	Loss: 0.12134295
2022-02-25 08:22:44,006 - ===> Validation after Training epoch: 25 	 Accuracy: 27.08%	Loss: 5.03568888
2022-02-25 08:36:14,522 - ===> Train Epoch: 26 	 Accuracy: 95.80%	Loss: 0.12045597
2022-02-25 08:49:44,899 - ===> Train Epoch: 27 	 Accuracy: 95.91%	Loss: 0.11636521
2022-02-25 09:03:15,273 - ===> Train Epoch: 28 	 Accuracy: 96.06%	Loss: 0.11297809
2022-02-25 09:16:45,423 - ===> Train Epoch: 29 	 Accuracy: 96.12%	Loss: 0.11010761
2022-02-25 09:30:15,735 - ===> Train Epoch: 30 	 Accuracy: 96.11%	Loss: 0.11003814
2022-02-25 09:31:58,725 - ===> Validation after Training epoch: 30 	 Accuracy: 26.73%	Loss: 5.24652958
2022-02-25 09:45:30,062 - ===> Train Epoch: 31 	 Accuracy: 96.22%	Loss: 0.10681837
2022-02-25 09:59:00,356 - ===> Train Epoch: 32 	 Accuracy: 96.16%	Loss: 0.10388186
2022-02-25 10:12:30,942 - ===> Train Epoch: 33 	 Accuracy: 96.34%	Loss: 0.10386483
2022-02-25 10:26:01,269 - ===> Train Epoch: 34 	 Accuracy: 96.45%	Loss: 0.09724841
2022-02-25 10:39:31,648 - ===> Train Epoch: 35 	 Accuracy: 96.42%	Loss: 0.09752371
2022-02-25 10:41:14,614 - ===> Validation after Training epoch: 35 	 Accuracy: 26.48%	Loss: 5.50602484
2022-02-25 10:54:44,925 - ===> Train Epoch: 36 	 Accuracy: 96.36%	Loss: 0.09846685
2022-02-25 11:08:15,391 - ===> Train Epoch: 37 	 Accuracy: 96.52%	Loss: 0.09580255
2022-02-25 11:21:45,423 - ===> Train Epoch: 38 	 Accuracy: 96.60%	Loss: 0.09479540
2022-02-25 11:35:18,333 - ===> Train Epoch: 39 	 Accuracy: 96.57%	Loss: 0.09540715
2022-02-25 11:48:48,514 - ===> Train Epoch: 40 	 Accuracy: 96.71%	Loss: 0.09198105
2022-02-25 11:50:32,412 - ===> Validation after Training epoch: 40 	 Accuracy: 26.71%	Loss: 5.69749689
2022-02-25 12:04:02,504 - ===> Train Epoch: 41 	 Accuracy: 96.58%	Loss: 0.09237795
2022-02-25 12:17:32,823 - ===> Train Epoch: 42 	 Accuracy: 96.61%	Loss: 0.08875675
2022-02-25 12:31:02,853 - ===> Train Epoch: 43 	 Accuracy: 96.63%	Loss: 0.08992363
2022-02-25 12:44:33,155 - ===> Train Epoch: 44 	 Accuracy: 96.64%	Loss: 0.08826894
2022-02-25 12:58:03,064 - ===> Train Epoch: 45 	 Accuracy: 96.69%	Loss: 0.08823659
2022-02-25 12:59:46,208 - ===> Validation after Training epoch: 45 	 Accuracy: 26.60%	Loss: 5.82037067
2022-02-25 13:13:16,767 - ===> Train Epoch: 46 	 Accuracy: 96.65%	Loss: 0.08683179
2022-02-25 13:26:47,103 - ===> Train Epoch: 47 	 Accuracy: 96.75%	Loss: 0.08578531
2022-02-25 13:40:17,342 - ===> Train Epoch: 48 	 Accuracy: 96.72%	Loss: 0.08583327
2022-02-25 13:53:47,387 - ===> Train Epoch: 49 	 Accuracy: 96.74%	Loss: 0.08449204
2022-02-25 14:07:17,643 - ===> Train Epoch: 50 	 Accuracy: 96.80%	Loss: 0.08263206
2022-02-25 14:09:00,728 - ===> Validation after Training epoch: 50 	 Accuracy: 27.31%	Loss: 6.01206303
2022-02-25 14:22:30,894 - ===> Train Epoch: 51 	 Accuracy: 96.76%	Loss: 0.08227967
2022-02-25 14:36:01,052 - ===> Train Epoch: 52 	 Accuracy: 96.74%	Loss: 0.08396173
2022-02-25 14:49:31,107 - ===> Train Epoch: 53 	 Accuracy: 96.95%	Loss: 0.08135823
2022-02-25 15:03:01,230 - ===> Train Epoch: 54 	 Accuracy: 96.78%	Loss: 0.08280431
2022-02-25 15:16:31,411 - ===> Train Epoch: 55 	 Accuracy: 96.79%	Loss: 0.08084556
2022-02-25 15:18:14,635 - ===> Validation after Training epoch: 55 	 Accuracy: 26.80%	Loss: 6.04945946
2022-02-25 15:31:44,749 - ===> Train Epoch: 56 	 Accuracy: 96.78%	Loss: 0.08027978
2022-02-25 15:45:14,939 - ===> Train Epoch: 57 	 Accuracy: 96.89%	Loss: 0.07915087
2022-02-25 15:58:45,251 - ===> Train Epoch: 58 	 Accuracy: 96.77%	Loss: 0.08105990
2022-02-25 16:12:15,238 - ===> Train Epoch: 59 	 Accuracy: 96.91%	Loss: 0.07847012
2022-02-25 16:25:45,643 - ===> Train Epoch: 60 	 Accuracy: 96.79%	Loss: 0.07923302
2022-02-25 16:27:28,909 - ===> Validation after Training epoch: 60 	 Accuracy: 26.71%	Loss: 6.06533718
2022-02-25 16:40:59,274 - ===> Train Epoch: 61 	 Accuracy: 96.80%	Loss: 0.07859158
2022-02-25 16:54:29,414 - ===> Train Epoch: 62 	 Accuracy: 96.82%	Loss: 0.07774993
2022-02-25 17:08:00,277 - ===> Train Epoch: 63 	 Accuracy: 96.90%	Loss: 0.07679427
2022-02-25 17:21:30,585 - ===> Train Epoch: 64 	 Accuracy: 96.99%	Loss: 0.07570131
2022-02-25 17:34:59,944 - ===> Train Epoch: 65 	 Accuracy: 97.03%	Loss: 0.07452895
2022-02-25 17:36:43,095 - ===> Validation after Training epoch: 65 	 Accuracy: 26.23%	Loss: 6.17737436
2022-02-25 17:50:14,124 - ===> Train Epoch: 66 	 Accuracy: 96.97%	Loss: 0.07477205
2022-02-25 18:03:44,262 - ===> Train Epoch: 67 	 Accuracy: 96.95%	Loss: 0.07537681
2022-02-25 18:17:14,445 - ===> Train Epoch: 68 	 Accuracy: 97.04%	Loss: 0.07419129
2022-02-25 18:30:44,662 - ===> Train Epoch: 69 	 Accuracy: 96.94%	Loss: 0.07403370
2022-02-25 18:44:15,531 - ===> Train Epoch: 70 	 Accuracy: 97.01%	Loss: 0.07266635
2022-02-25 18:45:58,540 - ===> Validation after Training epoch: 70 	 Accuracy: 26.73%	Loss: 6.31913280
2022-02-25 18:59:28,532 - ===> Train Epoch: 71 	 Accuracy: 96.90%	Loss: 0.07386642
